# doc.py
import streamlit as st

def display_documentation():
    """Exibe a documenta√ß√£o completa e formatada do projeto usando abas e colunas."""

    st.markdown("## <span class='material-symbols-outlined'>menu_book</span> Documenta√ß√£o Detalhada do Projeto", unsafe_allow_html=True)
    st.caption("Navegue pelas abas abaixo para explorar todos os aspectos do projeto, desde a configura√ß√£o at√© o uso e solu√ß√£o de problemas.")
    st.subheader(" ", divider="rainbow")

    tab_labels = [ # Emojis diretamente nos nomes das abas para melhor apelo visual
        "üåü Vis√£o Geral",
        "üõ†Ô∏è Tecnologias",
        "üñ•Ô∏è Config. Ambiente",
        "üß† Config. Modelos IA",
        "üöÄ Executando o App",
        "üß≠ Guia de Uso",
        "‚ùì FAQ/Problemas"
    ]
    tab_overview, tab_tech, tab_env_setup, tab_ia_setup, tab_running_app, tab_usage_guide, tab_faq = st.tabs(tab_labels)


    # --- Aba: Vis√£o Geral ---
    with tab_overview:
        col_ov1, col_ov2 = st.columns(2)

        with col_ov1:
            st.success("### **Prop√≥sito e Objetivos**", icon="üéØ")            
            st.markdown("""
            Este projeto foi concebido como resposta √† atividade da disciplina :blue[**T√≥picos Avan√ßados em Sistemas para Internet I**] do curso :blue[**Tecnologia em Sistemas para Internet**]. Fundamentalmente, √© uma ferramenta robusta e intuitiva para **transformar conte√∫do de √°udio em texto transcrito e, subsequentemente, em insights concisos atrav√©s da extra√ß√£o de pontos-chave**.
            
            O objetivo principal √© oferecer uma solu√ß√£o de c√≥digo aberto que demonstre a integra√ß√£o eficaz de tecnologias de ponta em Intelig√™ncia Artificial (IA) para processamento de linguagem natural e √°udio. A aplica√ß√£o √© acess√≠vel por meio de uma interface web interativa, priorizando a facilidade de uso e a execu√ß√£o local dos modelos para maior privacidade e controle do usu√°rio.

            **P√∫blico-Alvo Principal:**
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>school</span> Estudantes e Pesquisadores:** Para transcrever aulas, palestras, entrevistas e facilitar a an√°lise qualitativa e quantitativa de material de √°udio.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>business_center</span> Profissionais de Diversas √Åreas:** Para registrar e sumarizar reuni√µes, workshops, depoimentos ou qualquer conte√∫do falado relevante para suas atividades, otimizando o tempo e a reten√ß√£o de informa√ß√£o.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>campaign</span> Criadores de Conte√∫do e Jornalistas:** Para gerar legendas, transcrever entrevistas ou resumos de podcasts, v√≠deos e outros materiais de √°udio, agilizando o fluxo de trabalho.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>developer_mode_tv</span> Desenvolvedores e Entusiastas de IA:** Como um exemplo pr√°tico e um ponto de partida para explorar a aplica√ß√£o e integra√ß√£o de modelos como Whisper e LLMs via Ollama em projetos pr√≥prios.
            """, unsafe_allow_html=True)

        with col_ov2:
            st.success("### **Principais Benef√≠cios**", icon="‚ú®")
            st.markdown("""
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>schedule</span> Economia de Tempo:** Automatiza o processo manual e frequentemente demorado de transcri√ß√£o, liberando tempo para tarefas mais estrat√©gicas.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>accessibility_new</span> Acessibilidade Aprimorada:** Torna o conte√∫do de √°udio mais acess√≠vel para pessoas com defici√™ncia auditiva e facilita a pesquisa textual dentro do material falado.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>analytics</span> Efici√™ncia na An√°lise de Dados:** A extra√ß√£o de pontos-chave permite identificar rapidamente as informa√ß√µes cruciais e os temas centrais do √°udio.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>security</span> Privacidade e Controle Local:** Ao utilizar modelos que rodam localmente (especialmente com Ollama), os dados do usu√°rio permanecem em sua m√°quina, garantindo maior privacidade e controle.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>tune</span> Customiza√ß√£o e Flexibilidade:** Oferece op√ß√µes para selecionar diferentes modelos (tamanhos do Whisper, escolha do LLM no Ollama) de acordo com a necessidade espec√≠fica de precis√£o, velocidade e recursos dispon√≠veis.
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>code_off</span> Baixo Custo/Gratuito:** Utiliza ferramentas e modelos open-source, eliminando custos de APIs pagas para transcri√ß√£o e processamento de linguagem.
            """, unsafe_allow_html=True)
        
        st.subheader(" ", divider="rainbow")
        st.subheader("üîë Funcionalidades Detalhadas")
        
        # Funcionalidades em colunas, com cada feature em um container destacado
        cols_features_1, cols_features_2 = st.columns(2)
        
        with cols_features_1:
            with st.container(border=True):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>record_voice_over</span> Transcri√ß√£o de √Åudio Precisa", unsafe_allow_html=True)
                st.markdown("""
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>file_upload</span> Upload facilitado de arquivos de √°udio nos formatos `.wav` e `.mp3`.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>hearing_disabled</span> Utiliza√ß√£o do robusto modelo OpenAI Whisper para reconhecimento de fala.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>translate</span> Prioriza√ß√£o para o idioma Portugu√™s (`language='pt'`) para maior acur√°cia em conte√∫dos locais.
                """, unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True) 
            with st.container(border=True):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>psychology</span> Extra√ß√£o Inteligente de Pontos-Chave", unsafe_allow_html=True)
                st.markdown("""
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>hub</span> Integra√ß√£o com Modelos de Linguagem Grandes (LLMs) atrav√©s do Ollama para an√°lise sem√¢ntica.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>edit_note</span> Identifica√ß√£o e apresenta√ß√£o concisa dos principais t√≥picos e informa√ß√µes da transcri√ß√£o.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>dynamic_feed</span> Flexibilidade para o usu√°rio definir qual modelo LLM (ex: `llama3`, `mistral`) localmente dispon√≠vel no Ollama ser√° utilizado.
                """, unsafe_allow_html=True)

        with cols_features_2:
            with st.container(border=True):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>tune</span> Configura√ß√£o Flex√≠vel de Modelos", unsafe_allow_html=True)
                st.markdown("""
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>model_training</span> Sele√ß√£o do tamanho do modelo Whisper (`tiny`, `base`, `small`, `medium`, `large`) para balancear velocidade e precis√£o.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>settings_ethernet</span> Campo para especificar o nome do modelo Ollama a ser utilizado, conforme configurado localmente pelo usu√°rio.
                """, unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True) 
            with st.container(border=True):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>preview</span> Interface Clara e Feedback ao Usu√°rio", unsafe_allow_html=True)
                st.markdown("""
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>smart_display</span> Interface web interativa e amig√°vel constru√≠da com Streamlit.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>hourglass_top</span> Indicadores de progresso (spinners) com exibi√ß√£o de tempo decorrido durante as opera√ß√µes.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>play_circle</span> Player de √°udio integrado para verifica√ß√£o do arquivo carregado.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>notifications_active</span> Notifica√ß√µes (toasts) para informar sobre a conclus√£o de etapas.
                """, unsafe_allow_html=True)
        
        st.subheader(" ", divider="rainbow")
        st.subheader("üèóÔ∏è Arquitetura Simplificada do Sistema")
        st.markdown("""
        O funcionamento da aplica√ß√£o pode ser entendido atrav√©s de suas principais camadas e o fluxo de dados entre elas:
        """)

        arch_col1, arch_col2, arch_col3 = st.columns(3)
        with arch_col1:
            st.markdown("<div align='center'><strong><span class='material-symbols-outlined' style='font-size:1.5em; vertical-align:middle;'>wysiwyg</span><br>1. Frontend<br>(Interface do Usu√°rio)</strong></div>", unsafe_allow_html=True)
            st.caption("Desenvolvida com **Streamlit**. Coleta o √°udio e as configura√ß√µes do usu√°rio, e exibe os resultados finais.")
        with arch_col2:
            st.markdown("<div align='center'><strong><span class='material-symbols-outlined' style='font-size:1.5em; vertical-align:middle;'>graphic_eq</span><br>2. Transcri√ß√£o<br>(Processamento Local)</strong></div>", unsafe_allow_html=True)
            st.caption("Utiliza a biblioteca **OpenAI Whisper**. Converte o arquivo de √°udio em texto bruto diretamente na m√°quina do usu√°rio.")
        with arch_col3:
            st.markdown("<div align='center'><strong><span class='material-symbols-outlined' style='font-size:1.5em; vertical-align:middle;'>summarize</span><br>3. Pontos-Chave<br>(Processamento Local)</strong></div>", unsafe_allow_html=True)
            st.caption("Emprega **Ollama + LLM**. Recebe o texto transcrito e o processa para extrair os principais insights e pontos.")
        
        st.markdown("<br>", unsafe_allow_html=True)
        # O t√≠tulo do fluxograma centralizado pelo HTML
        st.markdown("<p style='text-align:center; font-weight:bold;'><span class='material-symbols-outlined' style='vertical-align:middle; font-size:1.2em;'>flowsheet</span> Fluxo de Dados da Aplica√ß√£o:</p>", unsafe_allow_html=True)
        
        # Usando colunas para centralizar o gr√°fico Graphviz e sua legenda
        # Ajuste as propor√ß√µes [0.5, 3, 0.5] conforme necess√°rio.
        # Isso significa que a coluna do meio (col_chart) ocupar√° 3 partes da largura,
        # enquanto as colunas laterais (espa√ßadores) ocupar√£o 0.5 parte cada.
        col_spacer1, col_chart, col_spacer2 = st.columns([0.5, 3, 0.5])

        with col_chart:
            st.graphviz_chart("""
                digraph {
                    rankdir="LR"; // Da esquerda para a direita

                    node [shape=box, style="rounded,filled", fillcolor="#E6F2FF", fontname="Arial", fontsize="10"];
                    edge [fontname="Arial", fontsize="9"];

                    // N√≥s representando os componentes
                    usuario [label="üë§ Usu√°rio", shape=circle, fillcolor="#FFEBE6"];
                    streamlit_app [label="üñ•Ô∏è Interface Streamlit", fillcolor="#D1FFD1"];
                    whisper_engine [label="üéôÔ∏è Motor Whisper (Local)", fillcolor="#FFF0E6"];
                    ollama_llm [label="üß† Ollama + LLM (Local)", fillcolor="#E6E6FF"];

                    // Arestas representando o fluxo de dados e intera√ß√µes
                    usuario -> streamlit_app [label=" Upload de √Åudio\\n+ Configura√ß√µes"];
                    streamlit_app -> whisper_engine [label="  Arquivo de √Åudio  "];
                    whisper_engine -> streamlit_app [label="  Texto Transcrito  "];
                    streamlit_app -> ollama_llm [label="  Texto Transcrito  "];
                    ollama_llm -> streamlit_app [label="  Pontos-Chave  "];
                }
            """)
            
            st.caption("Diagrama do fluxo de dados principal da aplica√ß√£o, da entrada do usu√°rio at√© a exibi√ß√£o dos resultados.")
            
             
    # --- Aba: Tecnologias ---
    with tab_tech:
        st.subheader("üõ†Ô∏è Stack Tecnol√≥gico Utilizado")
        st.markdown("""
        Este projeto √© o resultado da sinergia entre diversas ferramentas e bibliotecas de ponta,
        cada uma desempenhando um papel crucial na funcionalidade e experi√™ncia do usu√°rio.
        """)
        st.subheader(" ", divider="rainbow")

        col_tech1, col_tech2 = st.columns(2)
        with col_tech1:
            with st.expander("Python (Linguagem Principal)", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>code</span> Python", unsafe_allow_html=True)
                st.markdown("""
                Linguagem de programa√ß√£o vers√°til, poderosa e de alto n√≠vel, amplamente adotada em desenvolvimento web,
                ci√™ncia de dados, intelig√™ncia artificial e automa√ß√£o. Sua sintaxe clara e a vasta gama de bibliotecas
                (como PyTorch/TensorFlow, sobre os quais modelos como o Whisper s√£o constru√≠dos) o tornam ideal para este tipo de aplica√ß√£o.
                Neste projeto, Python √© a espinha dorsal que interconecta todos os componentes.
                """)

            with st.expander("OpenAI Whisper (Transcri√ß√£o de √Åudio)", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>mic_external_on</span> OpenAI Whisper", unsafe_allow_html=True)
                st.markdown("""
                Um modelo de Reconhecimento Autom√°tico de Fala (ASR) de √∫ltima gera√ß√£o, desenvolvido e treinado pela OpenAI.
                √â capaz de transcrever √°udio em m√∫ltiplos idiomas com not√°vel precis√£o, mesmo em condi√ß√µes de √°udio
                desafiadoras (ru√≠do, sotaques diversos). Sua arquitetura robusta e a disponibilidade de modelos de
                diferentes tamanhos permitem um equil√≠brio entre velocidade de processamento e acur√°cia da transcri√ß√£o.
                [Saiba mais sobre Whisper](https://openai.com/research/whisper).
                """)

            with st.expander("Requests (Comunica√ß√£o HTTP)", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>http</span> Requests", unsafe_allow_html=True)
                st.markdown("""
                Uma biblioteca Python elegante e simples para fazer requisi√ß√µes HTTP. Considerada o padr√£o de fato para
                intera√ß√µes HTTP em Python devido √† sua API amig√°vel. Neste projeto, √© essencial para permitir que
                a aplica√ß√£o Streamlit envie o texto transcrito para o servidor local do Ollama (que exp√µe uma API REST)
                e receba os pontos-chave gerados pelo LLM.
                """)

        with col_tech2:
            with st.expander("Streamlit (Interface Web)", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>dashboard_customize</span> Streamlit", unsafe_allow_html=True)
                st.markdown("""
                Um framework open-source em Python que permite transformar scripts de an√°lise de dados e modelos de IA
                em aplica√ß√µes web interativas e compartilh√°veis com um esfor√ßo m√≠nimo de codifica√ß√£o frontend.
                Sua facilidade de uso, vasta gama de widgets interativos (bot√µes, seletores, upload de arquivos, etc.)
                e capacidade de recarregamento r√°pido tornam o desenvolvimento e a prototipagem √°geis.
                [Visite Streamlit](https://streamlit.io).
                """)

            with st.expander("Ollama (LLMs Locais)", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>hub</span> Ollama", unsafe_allow_html=True)
                st.markdown("""
                Uma plataforma poderosa que simplifica drasticamente o processo de download, configura√ß√£o e execu√ß√£o
                de Modelos de Linguagem Grandes (LLMs) populares, como Llama, Mistral, Gemma, entre outros, diretamente
                na sua m√°quina local. Ollama promove a experimenta√ß√£o e o uso de IA generativa com maior privacidade,
                controle e sem a necessidade de depender de APIs externas ou custos associados. Suporta uma crescente
                biblioteca de modelos abertos. [Conhe√ßa o Ollama](https://ollama.com).
                """)
        
        st.subheader(" ", divider="rainbow")
        st.warning(
            """**Depend√™ncia Externa Essencial: FFmpeg**
            
            ‚ö†Ô∏è O `ffmpeg` √© uma su√≠te de software crucial para manipula√ß√£o de multim√≠dia. No contexto deste projeto,
            o Whisper depende do `ffmpeg` para decodificar e processar uma ampla variedade de formatos de arquivo de √°udio
            antes da transcri√ß√£o. Sua aus√™ncia ou configura√ß√£o incorreta no sistema resultar√° em falhas na
            transcri√ß√£o. As instru√ß√µes detalhadas de instala√ß√£o do `ffmpeg` podem ser encontradas na aba "Config. Ambiente".
            """, 
            icon="üö®"
        )

    # --- Aba: Configura√ß√£o do Ambiente ---
    with tab_env_setup:
        st.subheader("üñ•Ô∏è Configura√ß√£o do Ambiente de Desenvolvimento/Execu√ß√£o")
        st.markdown("Siga estes passos detalhados para preparar seu ambiente local e executar a aplica√ß√£o. Uma configura√ß√£o correta √© essencial para que todas as funcionalidades operem como esperado.")
        st.subheader(" ", divider="rainbow")

        # Primeiros 4 passos em duas colunas
        col_env1, col_env2 = st.columns(2)

        with col_env1:
            with st.expander("Passo 1: Instala√ß√£o do Python", expanded=False): # Manter o primeiro expandido
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>code</span> 1. Python", unsafe_allow_html=True)
                st.info("‚û°Ô∏è Certifique-se de ter Python instalado. Vers√µes **3.8 a 3.11** s√£o recomendadas. Voc√™ pode baixar Python em [python.org](https://www.python.org/downloads/).", icon="üêç")
                st.markdown("""
                - Ap√≥s a instala√ß√£o, √© crucial verificar se o Python e o `pip` (o gerenciador de pacotes do Python) est√£o corretamente configurados nas vari√°veis de ambiente do seu sistema (PATH). Abra um novo terminal ou prompt de comando e execute:
                  ```bash
                  python --version
                  pip --version
                  ```
                - Se os comandos n√£o forem reconhecidos, voc√™ precisar√° adicionar manualmente os diret√≥rios de instala√ß√£o do Python e da sua subpasta `Scripts` (onde o `pip` geralmente reside no Windows) √† vari√°vel de ambiente PATH do seu sistema.
                """)

            with st.expander("Passo 2: Cria√ß√£o de Ambiente Virtual (Recomendado)", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>eco</span> 2. Ambiente Virtual", unsafe_allow_html=True)
                st.success("üí° Para evitar conflitos de depend√™ncia entre diferentes projetos Python e manter seu ambiente global limpo, √© uma **excelente pr√°tica de desenvolvimento** usar um ambiente virtual dedicado para este projeto.", icon="üõ°Ô∏è")
                st.markdown("""
                **Benef√≠cios:**
                - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>shield</span> Isolamento:** As bibliotecas e suas vers√µes espec√≠ficas instaladas para este projeto n√£o interferir√£o com outros projetos Python ou com a instala√ß√£o global do Python no seu sistema.
                - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>repeat</span> Reprodutibilidade:** Facilita a recria√ß√£o do mesmo ambiente de desenvolvimento em outras m√°quinas ou por outros colaboradores, usando um arquivo `requirements.txt`.

                **Como criar e ativar (exemplo usando `venv`):**
                No seu terminal, navegue at√© a pasta onde voc√™ deseja criar o projeto (ou onde voc√™ j√° extraiu os arquivos) e execute:
                ```bash
                # 1. Criar o ambiente virtual (ser√° criada uma pasta chamada '.venv')
                python -m venv .venv

                # 2. Ativar o ambiente virtual:
                #    No Linux/macOS:
                source .venv/bin/activate
                #    No Windows (Prompt de Comando):
                #    .venv\\Scripts\\activate.bat
                #    No Windows (PowerShell):
                #    .venv\\Scripts\\Activate.ps1
                ```
                - <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>terminal</span> *Voc√™ normalmente ver√° o nome do ambiente (ex: `(.venv)`) no in√≠cio do prompt do seu terminal, indicando que ele est√° ativo.*
                - <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>playlist_add_check</span> *Todos os comandos `pip install` para este projeto devem ser executados com o ambiente virtual ativado.*
                - <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>toggle_off</span> Para desativar o ambiente virtual quando terminar de trabalhar no projeto, simplesmente digite `deactivate` no terminal.
                """, unsafe_allow_html=True)

        with col_env2:
            with st.expander("Passo 3: Obten√ß√£o do C√≥digo Fonte do Projeto", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>folder_zip</span> 3. C√≥digo Fonte do Projeto", unsafe_allow_html=True)
                st.markdown("""
                Voc√™ precisar√° dos arquivos da aplica√ß√£o (`app.py`, `doc.py`, etc.) para execut√°-la.
                - **<span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>archive</span> Se voc√™ recebeu os arquivos como um `.zip`:** Extraia o conte√∫do para uma pasta de sua prefer√™ncia no seu computador.
                - **<span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>hub</span> Se for um reposit√≥rio Git (exemplo):** Use o Git para clonar o reposit√≥rio (substitua a URL pelo link correto, se aplic√°vel).
                  ```bash
                  git clone [https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git](https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git)
                  cd NOME_DO_REPOSITORIO_CLONADO
                  ```
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>snippet_folder</span> A estrutura b√°sica de arquivos que voc√™ deve ter na pasta do projeto inclui, no m√≠nimo:
                    - `app.py` (o script principal da aplica√ß√£o Streamlit)
                    - `doc.py` (este arquivo de documenta√ß√£o)
                    - `requirements.txt` (arquivo de depend√™ncias Python, veja o pr√≥ximo passo)
                    - Opcionalmente, `config.py` (se usado para configura√ß√µes como o rodap√©).
                """, unsafe_allow_html=True)

            with st.expander("Passo 4: Instala√ß√£o das Depend√™ncias Python", expanded=False):
                st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>list_alt</span> 4. Instala√ß√£o das Depend√™ncias Python", unsafe_allow_html=True)
                st.markdown("""
                As bibliotecas Python externas necess√°rias para o funcionamento do projeto est√£o listadas em um arquivo `requirements.txt`.
                
                1.  **<span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>description</span> Crie o arquivo `requirements.txt`** na raiz do seu projeto com o seguinte conte√∫do:
                    ```text
streamlit
openai-whisper
requests
                    ```
                2.  **<span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>download</span> Instale as depend√™ncias:** Com o ambiente virtual (se voc√™ criou um) **ativado**, execute o seguinte comando no terminal:
                    ```bash
                    pip install -r requirements.txt
                    ```
                Isso instalar√° as seguintes bibliotecas e suas respectivas depend√™ncias:
                - **<span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>rocket_launch</span> Streamlit:** Framework utilizado para construir e servir a interface web interativa da aplica√ß√£o.
                - **<span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>mic</span> OpenAI Whisper:** Biblioteca da OpenAI para realizar a transcri√ß√£o de √°udio para texto de alta precis√£o.
                - **<span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>http</span> Requests:** Biblioteca para realizar chamadas HTTP, usada  para comunicar com a API local do servidor Ollama.
                """, unsafe_allow_html=True)
                st.caption("Nota: A depend√™ncia `ffmpeg`, que √© crucial para o Whisper, √© uma instala√ß√£o a n√≠vel de sistema e √© tratada no pr√≥ximo passo.")
        
        st.subheader(" ", divider="rainbow")

        with st.expander("Passo 5: Instala√ß√£o do FFmpeg (Depend√™ncia Cr√≠tica para Whisper)", expanded=False):
            st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>movie_filter</span> 5. FFmpeg", unsafe_allow_html=True)
            st.error("üõë **FFmpeg √© absolutamente essencial** para que a biblioteca Whisper possa processar arquivos de √°udio corretamente. \n\nSem o FFmpeg instalado e devidamente configurado no PATH do seu sistema, a funcionalidade de transcri√ß√£o provavelmente falhar√° ou n√£o suportar√° todos os formatos de √°udio.", icon="‚ö†Ô∏è")
            
            st.markdown("Instale o FFmpeg no seu sistema operacional:")
            
            # Instru√ß√µes do FFmpeg em tr√™s colunas
            col_ffmpeg_linux, col_ffmpeg_mac, col_ffmpeg_win = st.columns(3)

            with col_ffmpeg_linux:
                st.markdown("##### <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>terminal</span> Linux (Debian/Ubuntu)", unsafe_allow_html=True)
                st.markdown("""
                Execute no terminal:
                ```bash
                sudo apt update && sudo apt install ffmpeg
                ```
                """, unsafe_allow_html=True)
            
            with col_ffmpeg_mac:
                st.markdown("##### <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>desktop_mac</span> macOS (Homebrew)", unsafe_allow_html=True)
                st.markdown("""
                Se voc√™ usa o [Homebrew](https://brew.sh/index_pt-br):
                ```bash
                brew install ffmpeg
                ```
                """, unsafe_allow_html=True)

            with col_ffmpeg_win:
                st.markdown("##### <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>desktop_windows</span> Windows", unsafe_allow_html=True)
                st.markdown("""
                1.  <span class='material-symbols-outlined' style='font-size:0.9em; vertical-align:middle;'>download_for_offline</span> Baixe os bin√°rios (ex: de [Gyan.dev](https://www.gyan.dev/ffmpeg/builds/)).
                2.  <span class='material-symbols-outlined' style='font-size:0.9em; vertical-align:middle;'>folder_open</span> Extraia para uma pasta (ex: `C:\\ffmpeg`).
                3.  <span class='material-symbols-outlined' style='font-size:0.9em; vertical-align:middle;'>rule_folder</span> Adicione a pasta `bin` (ex: `C:\\ffmpeg\\bin`) ao PATH do sistema.
                4.  <span class='material-symbols-outlined' style='font-size:0.9em; vertical-align:middle;'>restart_alt</span> **Reinicie** terminais abertos ou o sistema.
                """, unsafe_allow_html=True)
            
            st.subheader(" ", divider="rainbow")
            st.markdown("""
            **<span class='material-symbols-outlined' style='vertical-align:middle;'>task_alt</span> Verificando a Instala√ß√£o do FFmpeg:**
            Para confirmar, abra um **novo** terminal e digite:
            ```bash
            ffmpeg -version
            ```
            Voc√™ dever√° ver informa√ß√µes sobre a vers√£o do FFmpeg. Se ocorrer um erro de "comando n√£o encontrado", revise a instala√ß√£o e a configura√ß√£o do PATH.
            """, unsafe_allow_html=True)

    # --- Aba: Configura√ß√£o dos Modelos IA ---
    with tab_ia_setup:
        st.subheader("üß† Configura√ß√£o dos Modelos de Intelig√™ncia Artificial")
        st.markdown("""
        Esta se√ß√£o detalha como configurar os modelos de IA necess√°rios para as funcionalidades de transcri√ß√£o (Whisper)
        e extra√ß√£o de pontos-chave (Ollama com LLMs). Uma configura√ß√£o correta √© crucial para o funcionamento do aplicativo.
        """)
        st.subheader(" ", divider="rainbow")

        col_whisper, col_ollama = st.columns(2)

        with col_whisper:
            st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>hearing</span> 1. Modelos Whisper (Transcri√ß√£o)", unsafe_allow_html=True)
            
            with st.expander("Detalhes e Considera√ß√µes sobre os Modelos Whisper", expanded=False):
                st.markdown("""
                Os modelos de transcri√ß√£o do OpenAI Whisper s√£o o cora√ß√£o da funcionalidade de convers√£o de √°udio para texto.
                Eles s√£o gerenciados pela pr√≥pria biblioteca `openai-whisper`.
                
                - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>file_download</span> Download Autom√°tico:** Ao selecionar um tamanho de modelo na interface do aplicativo (`tiny`, `base`, `small`, `medium`, `large`) pela primeira vez, o modelo correspondente ser√° baixado automaticamente.
                - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>wifi</span> Requisito de Internet:** √â necess√°ria uma conex√£o com a internet para este download inicial de cada modelo.
                - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>folder_managed</span> Local de Cache:** Os modelos baixados s√£o armazenados localmente para uso futuro, geralmente na pasta `~/.cache/whisper` (no diret√≥rio home do seu usu√°rio, dentro da pasta `.cache`).
                - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>tune</span> Considera√ß√µes sobre os Modelos:**
                    - Modelos menores (ex: `tiny`, `base`, `small`) s√£o **mais r√°pidos** e exigem **menos recursos** computacionais (RAM/VRAM), mas podem ser **menos precisos** na transcri√ß√£o.
                    - Modelos maiores (ex: `medium`, `large`) oferecem **maior precis√£o**, mas s√£o **significativamente mais lentos** e consomem **mais recursos**. O modelo `large` pode ser particularmente pesado para CPUs e se beneficia enormemente de uma GPU NVIDIA com suporte a CUDA.
                    - **Desempenho:** Os modelos s√£o otimizados para rodar em CPU, mas o desempenho, especialmente dos modelos `medium` e `large`, √© substancialmente melhor com uma GPU NVIDIA compat√≠vel.
                """, unsafe_allow_html=True)
                st.caption("O aplicativo est√° configurado para priorizar transcri√ß√µes em Portugu√™s (`language='pt'`).")

        with col_ollama:
            st.markdown("#### <span class='material-symbols-outlined' style='vertical-align:middle;'>hub</span> 2. Ollama e LLMs (Pontos-Chave)", unsafe_allow_html=True)
            st.markdown("""
            Ollama √© a plataforma utilizada para executar Modelos de Linguagem Grandes (LLMs) localmente em sua m√°quina.
            Estes LLMs analisam o texto transcrito para extrair os pontos-chave. <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>psychology</span>
            """, unsafe_allow_html=True)
            
            with st.expander("Etapa 2.1: Instala√ß√£o do Ollama", expanded=False):
                st.markdown("##### <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>system_update_alt</span> Guia de Instala√ß√£o", unsafe_allow_html=True)
                st.markdown("""
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>link</span> Visite o [site oficial do Ollama](https://ollama.com/download) e baixe o instalador para seu sistema operacional (Windows, macOS, Linux).
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>desktop_windows</span> Siga as instru√ß√µes de instala√ß√£o fornecidas.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>terminal</span> Ap√≥s a instala√ß√£o, abra um **novo terminal** e execute `ollama --version` para confirmar.
                """, unsafe_allow_html=True)

            with st.expander("Etapa 2.2: Download de Modelos LLM via Ollama", expanded=False):
                st.markdown("##### <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>model_training</span> Baixando os Modelos Necess√°rios", unsafe_allow_html=True)
                st.markdown("""
                Antes de usar um LLM com o aplicativo, voc√™ precisa baix√°-lo usando o Ollama. O aplicativo sugere `llama3` por padr√£o.
                <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>terminal</span> Abra seu terminal e execute:
                ```bash
                # Para baixar o Llama 3 (modelo 8B, ~4.7GB, bom equil√≠brio)
                ollama pull llama3

                # Para baixar o Mistral (outro modelo popular, ~4.1GB)
                ollama pull mistral

                # Para um modelo menor e mais r√°pido (ex: Qwen2 0.5B, ~0.4GB)
                ollama pull qwen2:0.5b
                ```
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>pageview</span> Explore mais modelos na [biblioteca Ollama](https://ollama.com/library).
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>badge</span> O nome usado no comando `pull` (ex: `llama3`) √© o que voc√™ deve inserir na interface do app.
                - **Tamanhos dos Modelos:** LLMs v√™m em diversos tamanhos (ex: 0.5B, 7B, 13B, 70B par√¢metros). Modelos maiores s√£o geralmente mais capazes, mas exigem mais RAM e poder de processamento. Verifique os requisitos.
                - **Atualizar um Modelo:** Para obter a vers√£o mais recente de um modelo: `ollama pull nome_do_modelo` (ou `nome_do_modelo:latest`).
                """, unsafe_allow_html=True)

            with st.expander("Etapa 2.3: Executando o Servidor Ollama", expanded=False):
                st.markdown("##### <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>dns</span> Execu√ß√£o e Verifica√ß√£o do Servidor", unsafe_allow_html=True)
                st.markdown("""
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>power</span> **Servi√ßo em Background (Padr√£o):** Em muitas instala√ß√µes, o Ollama inicia automaticamente.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>play_circle</span> **In√≠cio Manual / Ver Logs:** Se precisar iniciar manualmente ou quiser ver os logs em tempo real (√∫til para depura√ß√£o), abra um terminal e execute:
                  ```bash
                  ollama serve
                  ```
                  Se executar `ollama serve` em primeiro plano no terminal, voc√™ ver√° os logs de atividade do servidor diretamente.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>lan</span> **Verifica√ß√£o da Porta:** O servidor opera por padr√£o em `http://localhost:11434`.
                - <span class='material-symbols-outlined' style='font-size:1em; vertical-align:middle;'>list_alt</span> **Listar Modelos Baixados:** Para ver os modelos que voc√™ tem localmente:
                  ```bash
                  ollama list
                  ```
                """, unsafe_allow_html=True)
        
        st.subheader(" ", divider="rainbow") 
        st.warning(
            """
            **Cr√≠tico: Ollama e Modelos LLM**

            O servidor Ollama deve estar em execu√ß√£o, e o modelo LLM que voc√™ especificar na interface do aplicativo precisa ter sido previamente baixado com `ollama pull` e estar listado em `ollama list` para que a funcionalidade de extra√ß√£o de pontos-chave funcione corretamente. 
            - :red[‚ÄºÔ∏è **Caso contr√°rio, voc√™ encontrar√° erros de comunica√ß√£o ou o campo de pontos-chave ficar√° vazio.**]
            """, 
            icon="üö®"
        )

    # --- Aba: Executando a Aplica√ß√£o ---
    with tab_running_app: #
        st.subheader("üöÄ Executando a Aplica√ß√£o Streamlit") 
        st.markdown("""
        Com todos os pr√©-requisitos e configura√ß√µes do ambiente e dos modelos de IA conclu√≠dos (detalhados nas abas anteriores), voc√™ est√° pronto para iniciar o aplicativo.
        """) 
        st.subheader(" ", divider="rainbow")

        col_checklist, col_steps = st.columns([0.8, 1.2]) # Ajuste a propor√ß√£o se desejar

        with col_checklist:
            # T√≠tulo corrigido usando st.markdown para renderizar o √≠cone HTML e adicionando o emoji ‚úÖ manualmente
            st.markdown("#### <span class='material-symbols-outlined'>checklist</span> Checklist R√°pido Antes de Executar:", unsafe_allow_html=True)
            
            # A lista de marcadores abaixo j√° estava correta com unsafe_allow_html=True no seu st.markdown
            st.markdown("""
            - <span class='material-symbols-outlined' style='vertical-align:middle; font-size:1.1em;'>toggle_on</span> Ambiente virtual **ativado**?
            - <span class='material-symbols-outlined' style='vertical-align:middle; font-size:1.1em;'>dns</span> Servidor Ollama **rodando**?
            - <span class='material-symbols-outlined' style='vertical-align:middle; font-size:1.1em;'>download_done</span> Modelo LLM desejado **baixado** via Ollama (ver aba "Config. Modelos IA")?
            - <span class='material-symbols-outlined' style='vertical-align:middle; font-size:1.1em;'>folder_zip</span> Voc√™ est√° no **diret√≥rio correto** do projeto no terminal?
            - <span class='material-symbols-outlined' style='vertical-align:middle; font-size:1.1em;'>movie_filter</span> `ffmpeg` **instalado** e no PATH (ver aba "Config. Ambiente")?
            """, unsafe_allow_html=True)
            st.subheader(" ", divider="rainbow")
            st.markdown("##### <span class='material-symbols-outlined'>system_update_alt</span> Download de Modelos Whisper", unsafe_allow_html=True)
            st.caption("Lembre-se: os modelos Whisper s√£o baixados automaticamente no primeiro uso. Uma conex√£o com a internet ser√° necess√°ria nesse momento.")
            

        with col_steps:
            st.markdown(r"""
            1.  **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>power_settings_new</span> Ative o Ambiente Virtual:**
                Se voc√™ criou um (ex: `.venv`), certifique-se de que ele est√° ativo no seu terminal atual.
                ```bash
                # Exemplo para Linux/macOS:
                source .venv/bin/activate
                # Exemplo para Windows (PowerShell):
                # .\.venv\Scripts\Activate.ps1 
                ```
                
            2.  **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>fact_check</span> Verifique o Servidor Ollama:**
                Confirme que o servidor Ollama est√° em execu√ß√£o (conforme detalhado na aba "Config. Modelos IA").
            3.  **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>folder_open</span> Navegue at√© a Pasta do Projeto:**
                No seu terminal, use o comando `cd` para ir at√© o diret√≥rio onde o arquivo `app.py` est√° localizado.
                ```bash
                cd caminho/para/seu/projeto
                ```
            4.  **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>terminal</span> Execute o Comando Streamlit:**
                Digite o seguinte comando e pressione Enter:
                ```bash
                streamlit run app.py
                ```
                ou
                ```bash
                streamlit run app.py --server.fileWatcherType none
                ```
                 
                
                
                Este comando inicia o servidor web do Streamlit e, na maioria das vezes, abre a aplica√ß√£o automaticamente no seu navegador padr√£o.
            """, unsafe_allow_html=True)
        
        st.subheader(" ", divider="rainbow")

        st.success("üéâ **Aplica√ß√£o Iniciada! O que esperar:** üéâ", icon="‚úÖ") 
        st.markdown("""
        - Seu navegador web padr√£o dever√° abrir uma nova aba com a interface do aplicativo.
        - Se n√£o abrir automaticamente, o terminal (onde voc√™ executou `streamlit run app.py`) mostrar√° as URLs para acesso:
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>computer</span> Local URL:** Geralmente `http://localhost:8501`
            - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>wifi</span> Network URL:** Algo como `http://SEU_ENDERECO_IP_LOCAL:8501` (√∫til para acessar de outros dispositivos na mesma rede).
        - <span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>hourglass_empty</span> **Primeiro Carregamento:** Aguarde alguns instantes para a interface carregar completamente. O primeiro uso de um modelo Whisper ou o carregamento inicial de um modelo Ollama podem levar um pouco mais de tempo.
        """, unsafe_allow_html=True) 
        st.subheader(" ", divider="rainbow")

        st.markdown("#### <span class='material-symbols-outlined'>stop_circle</span> Parando a Aplica√ß√£o", unsafe_allow_html=True)
        st.markdown("""
        Para interromper o servidor Streamlit e fechar a aplica√ß√£o:
        - Volte para a janela do terminal onde voc√™ executou o comando `streamlit run app.py`.
        - Pressione as teclas `Ctrl` + `C`.
        - O terminal pode pedir uma confirma√ß√£o para encerrar o job; se sim, confirme (geralmente digitando `y` ou `s`).
        """)
        st.subheader(" ", divider="rainbow")

        st.markdown("#### <span class='material-symbols-outlined'>tips_and_updates</span> Dicas Adicionais ao Executar", unsafe_allow_html=True)
        st.markdown("""
        - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>refresh</span> Recarregar Altera√ß√µes no C√≥digo:** Se voc√™ editar os arquivos Python (`app.py`, `doc.py`, etc.) enquanto o Streamlit est√° rodando, a interface do Streamlit no navegador geralmente mostrar√° uma op√ß√£o "Rerun" no canto superior direito, ou pode tentar recarregar automaticamente. Se preferir, salvar o arquivo modificado e atualizar a p√°gina do navegador (F5 ou Cmd+R) tamb√©m funciona.
        - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>important_devices</span> Acesso em Outros Dispositivos:** A "Network URL" exibida no terminal √© √∫til se voc√™ quiser testar ou usar a aplica√ß√£o em um tablet, smartphone ou outro computador que esteja conectado √† mesma rede Wi-Fi/LAN.
        - **<span class='material-symbols-outlined' style='font-size:1.1em; vertical-align:middle;'>troubleshoot</span> Observando o Terminal:** Mantenha o terminal onde o Streamlit est√° rodando vis√≠vel. Ele exibir√° informa√ß√µes √∫teis, logs de acesso e, mais importante, mensagens de erro detalhadas caso algo n√£o funcione como esperado na aplica√ß√£o.
        """, unsafe_allow_html=True)

    # --- Aba: Guia de Uso ---
    with tab_usage_guide:
        st.subheader("üß≠ Guia de Uso da Interface do Aplicativo") 
        st.markdown("A interface foi projetada para ser intuitiva.  est√° um detalhamento das principais se√ß√µes e funcionalidades:") 

        col_usage1, col_usage2 = st.columns(2)

        with col_usage1:
            st.markdown("#### <span class='material-symbols-outlined'>view_sidebar</span> 1. Barra Lateral de Configura√ß√µes (Sidebar)", unsafe_allow_html=True) 
            with st.expander("Detalhes da Barra Lateral", expanded=False): 
                st.markdown("""
                Localizada √† esquerda da tela, a barra lateral cont√©m todas as op√ß√µes de configura√ß√£o antes do processamento:
                - **<span class='material-symbols-outlined'>mic</span> Selecione o Modelo Whisper:**
                    - Um menu suspenso permite escolher o tamanho do modelo Whisper a ser usado para a transcri√ß√£o (ex: `tiny`, `small`, `medium`).
                    - **Impacto:** Modelos menores s√£o mais r√°pidos mas menos precisos. Modelos maiores s√£o mais precisos mas mais lentos e exigem mais recursos computacionais.
                - **<span class='material-symbols-outlined'>hub</span> Nome do Modelo Ollama:**
                    - Um campo de texto onde voc√™ deve inserir o nome exato do modelo LLM que voc√™ baixou via Ollama e deseja usar para extrair os pontos-chave (ex: `llama3`, `mistral`, `qwen2:0.5b`).
                    - Este nome deve corresponder a um modelo listado por `ollama list`.
                - **<span class='material-symbols-outlined'>upload_file</span> Escolha um arquivo de √°udio:**
                    - Bot√£o para fazer upload de um arquivo de √°udio do seu computador.
                    - **Formatos Suportados:** `.wav` e `.mp3`.
                """, unsafe_allow_html=True) # Este j√° estava correto

        with col_usage2:
            st.markdown("#### <span class='material-symbols-outlined'>web_asset</span> 2. √Årea Principal de Intera√ß√£o", unsafe_allow_html=True) 
            with st.expander("Detalhes da √Årea Principal (Ap√≥s Upload e Processamento)", expanded=False): 
                st.markdown("""
                - **<span class='material-symbols-outlined'>play_circle</span> Player de √Åudio:**
                    - Ap√≥s o upload, um player de √°udio aparecer√°, permitindo que voc√™ ou√ßa o √°udio carregado antes ou depois do processamento.
                - **<span class='material-symbols-outlined'>rocket_launch</span> Bot√£o "Processar √Åudio":**
                    - Este √© o gatilho principal (indicado pelo emoji üöÄ no bot√£o real). Ao clicar nele, o processo de transcri√ß√£o e extra√ß√£o de pontos-chave √© iniciado.
                - **<span class='material-symbols-outlined'>hourglass_top</span> Indicadores de Progresso (Spinners):**
                    - Durante o processamento, spinners aparecer√£o indicando as etapas em execu√ß√£o.
                    - Estes spinners incluem a funcionalidade `show_time=True`, exibindo o tempo decorrido.
                - **<span class='material-symbols-outlined'>view_column</span> Resultados Exibidos em Colunas:**
                    - **Coluna da Transcri√ß√£o:** √Ä esquerda, o texto completo transcrito.
                    - **Coluna de Pontos-Chave:** √Ä direita, os pontos-chave identificados.
                - **<span class='material-symbols-outlined'>notifications</span> Notifica√ß√µes (Toasts):**
                    - Mensagens curtas e tempor√°rias para indicar a conclus√£o de etapas.
                """, unsafe_allow_html=True)  
        
        # Se√ß√£o "Acesso √† Documenta√ß√£o" abaixo das colunas, ocupando a largura total
        st.subheader(" ", divider="rainbow") 
        st.markdown("#### <span class='material-symbols-outlined'>menu_book</span> 3. Acesso √† Documenta√ß√£o", unsafe_allow_html=True) 
        st.markdown("""
        - No topo da p√°gina principal ou da p√°gina de documenta√ß√£o, voc√™ encontrar√° o bot√£o **"<span class='material-symbols-outlined'>visibility</span> Ver Documenta√ß√£o Interativa"** (ou similar, o texto do bot√£o √© definido em `app.py`).
        - Clicar neste bot√£o alterna a visualiza√ß√£o entre a interface principal do aplicativo e esta p√°gina de documenta√ß√£o detalhada.
        """, unsafe_allow_html=True)  
        
        
    # --- Aba: FAQ/Solu√ß√£o de Problemas ---
    with tab_faq:
        st.subheader("‚ùì Perguntas Frequentes e Solu√ß√£o de Problemas") #
        st.error("#### Encontrou um problema? Veja se estas dicas ajudam!", icon="üõ†Ô∏è") #

        col_faq1, col_faq2 = st.columns(2)

        with col_faq1:
            with st.expander("Problema: A aplica√ß√£o n√£o inicia ou mostra erro ao executar `streamlit run app.py`"): #
                st.markdown("""
                - **Verifique a instala√ß√£o do Streamlit:** `pip show streamlit`.
                - **Nome do arquivo:** Confirme que est√° no diret√≥rio correto e que o nome √© `app.py`.
                - **Ambiente Virtual:** Garanta que est√° ativado.
                - **Conflitos de Porta:** Verifique as mensagens no terminal.
                - **Logs do Terminal:** Observe para mensagens de erro detalhadas.
                """) #

            with st.expander("Problema: Transcri√ß√£o com Whisper est√° muito lenta"): #
                st.markdown("""
                - **Modelo Grande:** Modelos maiores s√£o inerentemente mais lentos.
                - **Recursos da M√°quina:** M√°quinas com poucos recursos ser√£o mais lentas.
                - **Primeira Execu√ß√£o:** Download do modelo adiciona tempo.
                - **Solu√ß√£o:** Tente um modelo Whisper menor.
                """) #
            
            with st.expander("Problema: Ollama n√£o responde, erro de comunica√ß√£o, ou nenhum ponto-chave √© extra√≠do"): #
                st.markdown("""
                - **Servidor Ollama Inativo:** Verifique com `ollama list`. Tente `ollama serve`.
                - **Modelo LLM n√£o Baixado:** Use `ollama pull NOME_DO_MODELO`.
                - **Nome do Modelo Incorreto:** Certifique-se de que o nome na interface √© exato.
                - **URL/Porta do Ollama:** Padr√£o √© `http://localhost:11434`.
                - **Recursos Insuficientes para o LLM:** Verifique os logs do `ollama serve`.
                """) #

        with col_faq2:
            with st.expander("Problema: FFmpeg n√£o encontrado / Erro na transcri√ß√£o relacionado a formato de √°udio"): #
                st.markdown("""
                - **Causa Principal:** FFmpeg n√£o instalado ou n√£o est√° no PATH.
                - **Solu√ß√£o:** Siga as instru√ß√µes de instala√ß√£o na aba "Config. Ambiente". Reinicie o terminal/PC. Verifique com `ffmpeg -version`.
                """) #

            with st.expander("Problema: Erro ao carregar modelo Whisper / Download falha"): #
                st.markdown("""
                - **Conex√£o com a Internet:** Necess√°ria para o download inicial.
                - **Espa√ßo em Disco:** Verifique `~/.cache/whisper`.
                - **Firewall/Proxy:** Podem estar bloqueando o download.
                - **Cache Corrompido:** Tente limpar `~/.cache/whisper`.
                """) #
            
            with st.expander("Problema: Qualidade da transcri√ß√£o n√£o √© ideal ou o idioma est√° incorreto"): #
                st.markdown("""
                - **Qualidade do √Åudio:** Ru√≠do, volume baixo, m√∫ltiplos falantes afetam a precis√£o.
                - **Tamanho do Modelo Whisper:** Modelos menores s√£o menos precisos.
                - **Idioma:** App configurado para **language='pt'**. Outros idiomas podem n√£o funcionar bem.
                """) #

        st.info("‚ÑπÔ∏è **Dica Geral:** Sempre verifique os logs (mensagens de texto) no terminal onde voc√™ executou `streamlit run app.py` e, se aplic√°vel, no terminal onde `ollama serve` est√° rodando. Eles frequentemente cont√™m mensagens de erro detalhadas que podem ajudar a diagnosticar o problema.", icon="üîç") #

